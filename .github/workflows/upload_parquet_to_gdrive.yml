name: Subir Parquet a Google Drive

on:
  schedule:
    - cron: "0 6 * * *"   # 06:00 UTC = 00:00 CDMX
  workflow_dispatch:       # permite lanzarlo manualmente

jobs:
  upload:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          lfs: true   # Necesario para bajar los JSON grandes

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas pyarrow

      - name: Convert JSON to Parquet
        run: |
          mkdir -p datos_parquet
          python <<EOF
          import pandas as pd

          files = {
              "contribucion/test/dataBases/indicadores_de_trading/bolsa_estados_unidos/bolsa_estados_unidos_ind_trading.json": "datos_parquet/bolsa_estados_unidos_ind_trading.parquet",
              "contribucion/test/dataBases/indicadores_de_trading/bolsa_mexicana_de_valores/bolsa_mexicana_de_valores_ind_trading.json": "datos_parquet/bolsa_mexicana_de_valores_ind_trading.parquet"
          }

          for src, dst in files.items():
              print(f"Procesando {src} -> {dst}")
              df = pd.read_json(src, lines=False)
              df.to_parquet(dst, engine="pyarrow", index=False)
          EOF

      - name: Install rclone
        run: |
          curl https://rclone.org/install.sh | sudo bash

      - name: Configure rclone
        run: |
          mkdir -p ~/.config/rclone
          echo "${{ secrets.RCLONE_CONF }}" > ~/.config/rclone/rclone.conf

      - name: Upload to Google Drive
        run: |
          rclone copy datos_parquet gdriveFinance: --progress
