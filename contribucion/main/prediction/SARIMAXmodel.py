import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from statsmodels.tsa.stattools import adfuller, acf, pacf
import numpy as np
import itertools
from statsmodels.tsa.statespace.sarimax import SARIMAX
import warnings
import pmdarima as pm
from joblib import Parallel, delayed
import time
import matplotlib.pyplot as plt
from typing import Optional

warnings.filterwarnings('ignore')

class SARIMAXmodel:
    def __init__(self,datos:pd.DataFrame,ticker:str):
        self.data = datos
        self.serie = self.data["Adj Close"]
        self.ticker = ticker
        self.modelo = None
        self.resultados = None
        self.periods = None
        self.df_predicciones = None

    def encontrar_s_optimo(self, periodos_a_probar=[5, 7, 21, 63, 126, 252]):
        """
        Analiza la serie para encontrar el per√≠odo estacional 's' m√°s probable.

        Args:
            serie (pd.Series): La serie de tiempo original.
            periodos_a_probar (list): Lista de per√≠odos 's' candidatos.

        Returns:
            int: El valor de 's' que muestra la autocorrelaci√≥n m√°s fuerte, o None si no hay
                 una estacionalidad clara.
        """
        serie = self.serie
        print("\n" + "=" * 70)
        print("BUSCANDO EL PER√çODO ESTACIONAL √ìPTIMO ('s')")
        print("=" * 70)

        mejor_s = None
        max_autocorr = 0.0

        try:
            # Calcular la autocorrelaci√≥n para todos los lags necesarios
            max_lag = max(periodos_a_probar) + 5
            autocorrelaciones = acf(serie.dropna(), nlags=max_lag, fft=True)

            print("Analizando la fuerza de la autocorrelaci√≥n en los lags estacionales:")

            for s in periodos_a_probar:
                if s < len(autocorrelaciones):
                    # Tomamos el valor absoluto de la autocorrelaci√≥n en el lag 's'
                    autocorr_en_s = abs(autocorrelaciones[s])
                    print(f"  - s = {s:<3}: Autocorrelaci√≥n = {autocorr_en_s:.4f}")

                    # Si esta autocorrelaci√≥n es la m√°s fuerte hasta ahora, la guardamos
                    if autocorr_en_s > max_autocorr:
                        max_autocorr = autocorr_en_s
                        mejor_s = s

        except Exception as e:
            print(f"Error durante la b√∫squeda de s: {e}")
            return None

        # Umbral m√≠nimo: si la autocorrelaci√≥n m√°s fuerte es muy d√©bil,
        # consideramos que no hay estacionalidad.
        umbral_minimo = 0.2
        if max_autocorr < umbral_minimo:
            print(f"\nNo se encontr√≥ una estacionalidad clara (autocorrelaci√≥n m√°xima < {umbral_minimo}).")
            return None

        print(f"\n‚úÖ 's' √≥ptimo recomendado: {mejor_s} (con autocorrelaci√≥n de {max_autocorr:.4f})")
        return mejor_s

    def encontrar_mejor_sarimax_rapido(self):
        """
        Usa auto_arima para encontrar el mejor modelo SARIMAX para una sola acci√≥n.
        Es mucho m√°s r√°pido que una b√∫squeda exhaustiva.
        """
        ticker = self.ticker
        serie = self.serie
        print(f"üöÄ Iniciando b√∫squeda para {ticker}...")
        try:
            # auto_arima encuentra los mejores p,d,q,P,D,Q autom√°ticamente.
            # Le damos el 's' (s_optimo) que ya conocemos o sospechamos.
            s_optimo = self.encontrar_s_optimo()  # Asumimos mensual como un buen candidato general

            modelo_auto = pm.auto_arima(
                serie,
                start_p=1, start_q=1,
                test='adf',  # Usa el test ADF para encontrar 'd'
                max_p=4, max_q=4,
                m=s_optimo,  # Aqu√≠ se define 's'
                start_P=0,
                seasonal=True,  # Activa la b√∫squeda estacional
                d=None,  # Permite que la librer√≠a encuentre 'd'
                D=None,  # Permite que la librer√≠a encuentre 'D'
                trace=False,  # No imprimir cada paso
                error_action='ignore',
                suppress_warnings=True,
                stepwise=True  # B√∫squeda escalonada (mucho m√°s r√°pida)
            )

            print(f"‚úÖ Mejor modelo para {ticker}: {modelo_auto.order} {modelo_auto.seasonal_order}")
            return {
                'ticker': ticker,
                'aic': modelo_auto.aic(),
                'order': modelo_auto.order,
                'seasonal_order': modelo_auto.seasonal_order
            }
        except Exception as e:
            print(f"‚ùå Error con {ticker}: {e}")
            return {'ticker': ticker, 'error': str(e)}

    def pronosticar_sarimax(self,periodos_a_predecir) -> pd.DataFrame:
        """
        Crea, entrena y pronostica con un modelo SARIMAX dado los par√°metros.

        Args:
            datos (pd.Series): La serie de tiempo original para el entrenamiento.
            order (tuple): Tupla (p, d, q) del componente no estacional.
            seasonal_order (tuple): Tupla (P, D, Q, s) del componente estacional.
            periodos_a_predecir (int): N√∫mero de per√≠odos futuros a pronosticar.

        Returns:
            pd.DataFrame: Un DataFrame con las predicciones, l√≠mites inferiores
                          y superiores del intervalo de confianza.
        """
        datos = self.serie
        parametros = self.encontrar_mejor_sarimax_rapido()
        order = parametros["order"]
        seasonal_order = parametros["seasonal_order"]
        self.periods = periodos_a_predecir

        print("üìã Par√°metros de SARIMAX a utilizar:")
        print(f"  - No estacional (p, d, q): {order}")
        print(f"  - Estacional (P, D, Q, s): {seasonal_order}")
        print("-" * 50)

        try:
            # 1. Instanciar y entrenar el modelo SARIMAX de statsmodels
            # El argumento `enforce_stationarity=False` puede ser √∫til
            # si `auto_arima` encuentra `d > 0`.
            modelo = SARIMAX(
                datos,
                order=order,
                seasonal_order=seasonal_order,
                enforce_stationarity=False,
                enforce_invertibility=False
            )

            print("üîÑ Entrenando el modelo...")
            self.resultados = modelo.fit(disp=False)
            print("‚úÖ Modelo entrenado exitosamente.")

            # 2. Generar predicciones
            print(f"üîÆ Generando predicciones para los pr√≥ximos {periodos_a_predecir} per√≠odos...")

            # El m√©todo get_forecast() es m√°s robusto para generar predicciones
            # y sus intervalos de confianza.
            pronostico_resultados = self.resultados.get_forecast(steps=periodos_a_predecir)

            # Extraer los pron√≥sticos y los intervalos de confianza
            pronosticos = pronostico_resultados.predicted_mean
            intervalos_confianza = pronostico_resultados.conf_int()

            # Unir todos los resultados en un solo DataFrame

            last_date = self.data['Date'].iloc[-1]

            datesPredicted = pd.date_range(start= pd.to_datetime(last_date) + pd.Timedelta(days=1), periods=self.periods)

            self.df_predicciones = pd.DataFrame({
                'Date':datesPredicted,
                'frcst_sarimax_01_mean': pronosticos,
                'frcst_sarimax_01_low': intervalos_confianza['lower Adj Close'],
                'frcst_sarimax_01_upper': intervalos_confianza['upper Adj Close']
            })

            print("‚úÖ Pron√≥sticos y l√≠mites generados.")
            return self.df_predicciones

        except Exception as e:
            print(f"‚ùå Ocurri√≥ un error durante el pron√≥stico: {e}")
            return None

    def evaluar_modelo(self):
        """
        Eval√∫a el modelo SARIMAX usando datos de entrenamiento (in-sample).
        """
        if self.resultados is None:
            print("‚ö†Ô∏è Primero entrena el modelo usando 'pronosticar_sarimax()'")
            return None

        # Predicci√≥n dentro de la muestra
        predicciones_in_sample = self.resultados.predict(start=0, end=len(self.serie)-1)
        reales = self.serie

        # Calcular m√©tricas
        mae = mean_absolute_error(reales, predicciones_in_sample)
        rmse = np.sqrt(mean_squared_error(reales, predicciones_in_sample))
        mape = np.mean(np.abs((reales - predicciones_in_sample) / reales)) * 100
        r2 = r2_score(reales, predicciones_in_sample)

        print("\nüìä Evaluaci√≥n del Modelo (In-sample):")
        print(f"  - AIC:  {self.resultados.aic:.2f}")
        print(f"  - BIC:  {self.resultados.bic:.2f}")
        print(f"  - Mean Absolute Error:  {mae:.4f}")
        print(f"  - Root Mean Squared Error: {rmse:.4f}")
        print(f"  - Mean Absolute Porcentual Error: {mape:.2f}%")
        print(f"  - R¬≤:   {r2:.4f}")

        return {
            'AIC': self.resultados.aic,
            'BIC': self.resultados.bic,
            'MAE': mae,
            'RMSE': rmse,
            'MAPE': mape,
            'R2': r2
        }

    def storagePredictions(self, data: Optional[pd.DataFrame] = None):

        datos_trabajo = data.copy() if data is not None else self._data_original.copy()

        if not datos_trabajo.empty:
            datos_trabajo['ticker'] = self.ticker
            # Usar solo pathlib.Path para consistencia
            subcarpeta = self.rutaSalida / self.nombre
            subcarpeta.mkdir(parents=True, exist_ok=True)
            ruta_archivo = subcarpeta / f"{self.nombre}_{self.ticker.replace('.MX', '')}_predictions.json"

            df_total = datos_trabajo

            # Crear lista documentos para guardar como NDJSON

            with open(ruta_archivo, 'w', encoding='utf-8') as f:
                for _, row in df_total.iterrows():
                    date_obj = pd.to_datetime(row['Date'], utc=True)

                    document = {
                        "Date": date_obj.strftime('%Y-%m-%d'),
                        "ticker": row['ticker'],
                        "frcst_sarimax_01_mean": float(row["frcst_sarimax_01_mean"]) if pd.notna(row["frcst_sarimax_01_mean"]) else None,
                        "frcst_sarimax_01_low": float(row["frcst_sarimax_01_low"]) if pd.notna(row["frcst_sarimax_01_low"]) else None,
                        "frcst_sarimax_01_upper": float(row["frcst_sarimax_01_upper"]) if pd.notna(row["frcst_sarimax_01_upper"]) else None
                    }
                    f.write(json.dumps(document, ensure_ascii=False) + "\n")

            print(
                f"[Almacenamiento Pron√≥sticos] [{self.nombre}] ‚úÖ Guardado como NDJSON compatible MongoDB en: {self.rutaSalida}")
            print(f"[Almacenamiento Pron√≥sticos] Total documentos: {len(df_total)}")

        else:
            print(f"[Almacenamiento Pron√≥sticos] [{self.nombre}] ‚ö†Ô∏è No se encontraron datos para {self.ticker}")